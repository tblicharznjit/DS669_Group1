{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMP4B4iF1Pm1"
      },
      "outputs": [],
      "source": [
        "# analyze_dataset.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "\n",
        "CSV = \"finalData.csv\"\n",
        "RANDOM_STATE = 42\n",
        "NBINS = 25  # 5 fluids x 5 vaso\n",
        "\n",
        "# columns to drop\n",
        "DROP_COLS = [\n",
        "    \"Unnamed: 0\", \"hadm_id\", \"icustay_id\", \"subject_id\",\n",
        "    \"HCO3\",  # teammate requested\n",
        "    \"race_asian\", \"race_black\", \"race_latino\", \"race_white\", \"race_other\"\n",
        "]\n",
        "\n",
        "# load\n",
        "df = pd.read_csv(CSV)\n",
        "\n",
        "# keep 90D_Mortality as label (1=death, 0=alive)\n",
        "assert \"90D_Mortality\" in df.columns, \"90D_Mortality missing\"\n",
        "\n",
        "# drop columns if present\n",
        "for c in DROP_COLS:\n",
        "    if c in df.columns:\n",
        "        df.drop(columns=c, inplace=True)\n",
        "\n",
        "# fill simple NaNs with column means for features\n",
        "feature_cols = [c for c in df.columns if c not in [\"90D_Mortality\", \"Death\"]]\n",
        "df[feature_cols] = df[feature_cols].astype(float)\n",
        "df[feature_cols] = df[feature_cols].fillna(df[feature_cols].mean())\n",
        "\n",
        "# make fluid bins from TotalInput (if missing, fallback to zeros)\n",
        "if \"TotalInput\" in df.columns:\n",
        "    # quantile bins 0..4 (per entire dataset)\n",
        "    fluid_bin = pd.qcut(df[\"TotalInput\"].rank(method=\"first\"), 5, labels=False)\n",
        "else:\n",
        "    fluid_bin = pd.Series(np.zeros(len(df), dtype=int))\n",
        "\n",
        "# dataset has no vaso input; set historical vaso_bin=0\n",
        "vaso_bin = pd.Series(np.zeros(len(df), dtype=int))\n",
        "\n",
        "# combine to 25-action index a = fluid + 5*vaso\n",
        "Action = (fluid_bin.values + 5 * vaso_bin.values).astype(int)\n",
        "\n",
        "# reward proxy: +24 alive, -24 death (paperâ€™s terminal reward scale)\n",
        "y = df[\"90D_Mortality\"].astype(int).values\n",
        "reward = np.where(y == 0, 24.0, -24.0)\n",
        "\n",
        "# features X (remove label)\n",
        "X = df.drop(columns=[\"90D_Mortality\"])\n",
        "\n",
        "# next-state (very simple: shift by 1 as a placeholder)\n",
        "Xnext = X.shift(-1).fillna(method=\"ffill\")\n",
        "\n",
        "# split\n",
        "X_train, X_tmp, y_train, y_tmp, A_train, A_tmp, Xnext_train, Xnext_tmp = train_test_split(\n",
        "    X, y, Action, Xnext, test_size=0.3, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "X_val, X_test, y_val, y_test, A_val, A_test, Xnext_val, Xnext_test = train_test_split(\n",
        "    X_tmp, y_tmp, A_tmp, Xnext_tmp, test_size=0.5, random_state=RANDOM_STATE, stratify=y_tmp\n",
        ")\n",
        "\n",
        "# normalize features (fit on train)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
        "X_val_scaled   = pd.DataFrame(scaler.transform(X_val),   columns=X_val.columns,   index=X_val.index)\n",
        "X_test_scaled  = pd.DataFrame(scaler.transform(X_test),  columns=X_test.columns,  index=X_test.index)\n",
        "\n",
        "Xnext_train_scaled = pd.DataFrame(scaler.transform(Xnext_train), columns=Xnext_train.columns, index=Xnext_train.index)\n",
        "Xnext_val_scaled   = pd.DataFrame(scaler.transform(Xnext_val),   columns=Xnext_val.columns,   index=Xnext_val.index)\n",
        "Xnext_test_scaled  = pd.DataFrame(scaler.transform(Xnext_test),  columns=Xnext_test.columns,  index=Xnext_test.index)\n",
        "\n",
        "# pack\n",
        "D = {\n",
        "    \"nbins\": NBINS,\n",
        "    \"X_train\": X_train_scaled, \"X_val\": X_val_scaled, \"X_test\": X_test_scaled,\n",
        "    \"Xnext_train\": Xnext_train_scaled, \"Xnext_val\": Xnext_val_scaled, \"Xnext_test\": Xnext_test_scaled,\n",
        "    \"y_train\": y_train, \"y_val\": y_val, \"y_test\": y_test,\n",
        "    \"Action_train\": A_train, \"Action_val\": A_val, \"Action_test\": A_test,\n",
        "}\n",
        "\n",
        "with open(\"requiredFile.pkl\", \"wb\") as f:\n",
        "    pickle.dump(D, f)\n",
        "\n",
        "print(\"Saved requiredFile.pkl with 25-action space (vaso_bin=0 historically) and normalized splits.\")\n"
      ]
    }
  ]
}