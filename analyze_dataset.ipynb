{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XMP4B4iF1Pm1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lf/wmkwxwwx63g16wbm61mzyxrm0000gn/T/ipykernel_29484/4097228734.py:56: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  Xnext = X.shift(-1).fillna(method=\"ffill\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved requiredFile.pkl with 25-action space (vaso_bin=0 historically) and normalized splits.\n"
          ]
        }
      ],
      "source": [
        "# analyze_dataset.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "\n",
        "CSV = \"finalData.csv\"\n",
        "RANDOM_STATE = 42\n",
        "NBINS = 25  # 5 fluids x 5 vaso\n",
        "\n",
        "# columns to drop\n",
        "DROP_COLS = [\n",
        "    \"Unnamed: 0\", \"hadm_id\", \"icustay_id\", \"subject_id\",\n",
        "    \"HCO3\",  \n",
        "    \"race_asian\", \"race_black\", \"race_latino\", \"race_white\", \"race_other\"\n",
        "]\n",
        "\n",
        "# load\n",
        "df = pd.read_csv(CSV)\n",
        "\n",
        "# keep 90D_Mortality as label (1=death, 0=alive)\n",
        "assert \"90D_Mortality\" in df.columns, \"90D_Mortality missing\"\n",
        "\n",
        "# drop columns if present\n",
        "for c in DROP_COLS:\n",
        "    if c in df.columns:\n",
        "        df.drop(columns=c, inplace=True)\n",
        "\n",
        "# fill simple NaNs with column means for features\n",
        "feature_cols = [c for c in df.columns if c not in [\"90D_Mortality\", \"Death\"]]\n",
        "df[feature_cols] = df[feature_cols].astype(float)\n",
        "df[feature_cols] = df[feature_cols].fillna(df[feature_cols].mean())\n",
        "\n",
        "# make fluid bins from TotalInput (if missing, fallback to zeros)\n",
        "if \"TotalInput\" in df.columns:\n",
        "    # quantile bins 0..4 (per entire dataset)\n",
        "    fluid_bin = pd.qcut(df[\"TotalInput\"].rank(method=\"first\"), 5, labels=False)\n",
        "else:\n",
        "    fluid_bin = pd.Series(np.zeros(len(df), dtype=int))\n",
        "\n",
        "# dataset has no vaso input; set historical vaso_bin=0\n",
        "vaso_bin = pd.Series(np.zeros(len(df), dtype=int))\n",
        "\n",
        "# combine to 25-action index a = fluid + 5*vaso\n",
        "Action = (fluid_bin.values + 5 * vaso_bin.values).astype(int)\n",
        "\n",
        "# reward proxy: +24 alive, -24 death (paperâ€™s terminal reward scale)\n",
        "y = df[\"90D_Mortality\"].astype(int).values\n",
        "reward = np.where(y == 0, 24.0, -24.0)\n",
        "\n",
        "# features X (remove label)\n",
        "X = df.drop(columns=[\"90D_Mortality\"])\n",
        "\n",
        "# next-state (very simple: shift by 1 as a placeholder)\n",
        "Xnext = X.shift(-1).fillna(method=\"ffill\")\n",
        "\n",
        "# split\n",
        "X_train, X_tmp, y_train, y_tmp, A_train, A_tmp, Xnext_train, Xnext_tmp = train_test_split(\n",
        "    X, y, Action, Xnext, test_size=0.3, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "X_val, X_test, y_val, y_test, A_val, A_test, Xnext_val, Xnext_test = train_test_split(\n",
        "    X_tmp, y_tmp, A_tmp, Xnext_tmp, test_size=0.5, random_state=RANDOM_STATE, stratify=y_tmp\n",
        ")\n",
        "\n",
        "# normalize features (fit on train)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
        "X_val_scaled   = pd.DataFrame(scaler.transform(X_val),   columns=X_val.columns,   index=X_val.index)\n",
        "X_test_scaled  = pd.DataFrame(scaler.transform(X_test),  columns=X_test.columns,  index=X_test.index)\n",
        "\n",
        "Xnext_train_scaled = pd.DataFrame(scaler.transform(Xnext_train), columns=Xnext_train.columns, index=Xnext_train.index)\n",
        "Xnext_val_scaled   = pd.DataFrame(scaler.transform(Xnext_val),   columns=Xnext_val.columns,   index=Xnext_val.index)\n",
        "Xnext_test_scaled  = pd.DataFrame(scaler.transform(Xnext_test),  columns=Xnext_test.columns,  index=Xnext_test.index)\n",
        "\n",
        "# pack\n",
        "D = {\n",
        "    \"nbins\": NBINS,\n",
        "    \"X_train\": X_train_scaled, \"X_val\": X_val_scaled, \"X_test\": X_test_scaled,\n",
        "    \"Xnext_train\": Xnext_train_scaled, \"Xnext_val\": Xnext_val_scaled, \"Xnext_test\": Xnext_test_scaled,\n",
        "    \"y_train\": y_train, \"y_val\": y_val, \"y_test\": y_test,\n",
        "    \"Action_train\": A_train, \"Action_val\": A_val, \"Action_test\": A_test,\n",
        "}\n",
        "\n",
        "with open(\"requiredFile.pkl\", \"wb\") as f:\n",
        "    pickle.dump(D, f)\n",
        "\n",
        "print(\"Saved requiredFile.pkl with 25-action space (vaso_bin=0 historically) and normalized splits.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# My approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "vaso = pd.read_csv('vaso.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "vaso['avg_vaso_rate'] = vaso[['rate_norepinephrine', 'rate_epinephrine', 'rate_dopamine', 'rate_dobutamine']].max(axis=1)\n",
        "vaso = vaso[['icustay_id', 'bin', 'avg_vaso_rate']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('finalData.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'hadm_id', 'icustay_id', 'subject_id', 'Age', 'Death',\n",
              "       'Gender', 'race_asian', 'race_black', 'race_latino', 'race_white',\n",
              "       'race_other', '90D_Mortality', 'Weight', 'bin', 'PH', 'PaO2', 'PaCO2',\n",
              "       'PaO2/FiO2', 'ArterialBE', 'HCO3', 'FiO2', 'HGB', 'Chloride', 'Calcium',\n",
              "       'Magnesium', 'SGPT', 'SGOT', 'Temperature', 'HR', 'RR', 'SBP', 'DBP',\n",
              "       'MBP', 'ShockIndex', 'SpO2', 'AL', 'BUN', 'Creatinine', 'Platelet',\n",
              "       'WBC', 'Potassium', 'Sodium', 'Glucose', 'PTT', 'PT', 'INR', 'TB', 'CB',\n",
              "       'TotalInput', 'TotalOutput', '4hourlyOutput', 'SOFA', 'SIRS', 'GCS'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.merge(vaso, on=['icustay_id', 'bin'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['avg_vaso_rate'] = df['avg_vaso_rate'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "def discretize_iv(x):\n",
        "    if x == 0: return 0\n",
        "    elif x <= 50: return 1\n",
        "    elif x <= 180: return 2\n",
        "    elif x <= 530: return 3\n",
        "    else: return 4\n",
        "\n",
        "def discretize_vaso(x):\n",
        "    if x == 0: return 0\n",
        "    elif x <= 0.08: return 1\n",
        "    elif x <= 0.22: return 2\n",
        "    elif x <= 0.45: return 3\n",
        "    else: return 4\n",
        "\n",
        "df['iv_bin'] = df['TotalInput'].apply(discretize_iv)\n",
        "df['vaso_bin'] = df['avg_vaso_rate'].apply(discretize_vaso)\n",
        "df['Action'] = df['iv_bin'] * 5 + df['vaso_bin']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sanity check\n",
        "df = df.groupby('icustay_id').filter(lambda x: len(x) == 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'hadm_id', 'icustay_id', 'subject_id', 'Age', 'Death',\n",
              "       'Gender', 'race_asian', 'race_black', 'race_latino', 'race_white',\n",
              "       'race_other', '90D_Mortality', 'Weight', 'bin', 'PH', 'PaO2', 'PaCO2',\n",
              "       'PaO2/FiO2', 'ArterialBE', 'HCO3', 'FiO2', 'HGB', 'Chloride', 'Calcium',\n",
              "       'Magnesium', 'SGPT', 'SGOT', 'Temperature', 'HR', 'RR', 'SBP', 'DBP',\n",
              "       'MBP', 'ShockIndex', 'SpO2', 'AL', 'BUN', 'Creatinine', 'Platelet',\n",
              "       'WBC', 'Potassium', 'Sodium', 'Glucose', 'PTT', 'PT', 'INR', 'TB', 'CB',\n",
              "       'TotalInput', 'TotalOutput', '4hourlyOutput', 'SOFA', 'SIRS', 'GCS',\n",
              "       'avg_vaso_rate', 'iv_bin', 'vaso_bin', 'Action'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "state_cols = [\n",
        "    'Age', 'Gender', 'race_asian', 'race_black', 'race_latino', 'race_white',\n",
        "    'race_other', 'Weight', 'PH', 'PaO2', 'PaCO2',\n",
        "    'PaO2/FiO2', 'ArterialBE', 'HCO3', 'FiO2', 'HGB', 'Chloride', 'Calcium',\n",
        "    'Magnesium', 'SGPT', 'SGOT', 'Temperature', 'HR', 'RR', 'SBP', 'DBP',\n",
        "    'MBP', 'ShockIndex', 'SpO2', 'AL', 'BUN', 'Creatinine', 'Platelet',\n",
        "    'WBC', 'Potassium', 'Sodium', 'Glucose', 'PTT', 'PT', 'INR', 'TB', 'CB',\n",
        "    'TotalInput', 'TotalOutput', '4hourlyOutput', 'SOFA', 'SIRS', 'GCS'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "groups = df.groupby('icustay_id')\n",
        "patient_ids = {key: idx for idx, key in enumerate(groups.groups.keys())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_list = []\n",
        "Xnext_list = []\n",
        "Action_list = []\n",
        "ActionNext_list = []\n",
        "Reward_list = []\n",
        "Done_list = []\n",
        "Bloc_list = []\n",
        "SOFA_list = []\n",
        "\n",
        "for icustay_id, group in groups:\n",
        "    group = group.sort_values('bin')\n",
        "    if len(group) != 20:\n",
        "        continue\n",
        "    \n",
        "    states = group[state_cols].values\n",
        "    sofas = group['SOFA'].values\n",
        "    mortality = group['90D_Mortality'].iloc[0]\n",
        "    actions = group['Action'].values\n",
        "    \n",
        "    bloc_id = patient_ids[icustay_id]\n",
        "    \n",
        "    for t in range(20):\n",
        "        s = states[t]\n",
        "        a = actions[t]\n",
        "        sofa_t = sofas[t]\n",
        "        \n",
        "        if t < 19:\n",
        "            r = 0.6 * (sofa_t - sofas[t + 1])\n",
        "            d = 0\n",
        "            s_next = states[t + 1]\n",
        "            a_next = actions[t + 1]\n",
        "        else:\n",
        "            r = -24 if mortality == 1 else 24\n",
        "            d = 1\n",
        "            s_next = np.zeros_like(s)\n",
        "            a_next = 0\n",
        "        \n",
        "        X_list.append(s)\n",
        "        Xnext_list.append(s_next)\n",
        "        Action_list.append(a)\n",
        "        ActionNext_list.append(a_next)\n",
        "        Reward_list.append(r)\n",
        "        Done_list.append(d)\n",
        "        Bloc_list.append(bloc_id)\n",
        "        SOFA_list.append(sofa_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "requiredFile.pkl created.\n"
          ]
        }
      ],
      "source": [
        "MIMICtable = {\n",
        "    'X': np.array(X_list),\n",
        "    'Xnext': np.array(Xnext_list),\n",
        "    'Action': np.array(Action_list),\n",
        "    'ActionNext': np.array(ActionNext_list),\n",
        "    'Reward': np.array(Reward_list),\n",
        "    'Done': np.array(Done_list),\n",
        "    'Bloc': np.array(Bloc_list),\n",
        "    'SOFA': np.array(SOFA_list)\n",
        "}\n",
        "\n",
        "with open('requiredFile.pkl', 'wb') as f:\n",
        "    pickle.dump(MIMICtable, f)\n",
        "print('requiredFile.pkl created.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
