{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XMP4B4iF1Pm1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Running exp1_baseline (epochs=100, gamma=0.99, lr=1e-05, seed=42) ===\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Dist_DQN.__init__() got an unexpected keyword argument 'lr'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 125\u001b[39m\n\u001b[32m    122\u001b[39m outdir = os.path.join(\u001b[33m\"\u001b[39m\u001b[33mruns\u001b[39m\u001b[33m\"\u001b[39m, name); ensure_dir(outdir)\n\u001b[32m    123\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Running \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (epochs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, gamma=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[33m'\u001b[39m\u001b[33mgamma\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, seed=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[33m'\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m model = \u001b[43mDist_DQN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mXtr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_actions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_actions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgamma\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m log_path = os.path.join(outdir, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_training_log.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    129\u001b[39m \u001b[38;5;28mopen\u001b[39m(log_path, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m).close()\n",
            "\u001b[31mTypeError\u001b[39m: Dist_DQN.__init__() got an unexpected keyword argument 'lr'"
          ]
        }
      ],
      "source": [
        "# train_runner_multi.py\n",
        "import os, pickle, numpy as np, torch, matplotlib.pyplot as plt, pandas as pd\n",
        "from matplotlib import cm, colors\n",
        "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
        "from ID3QNE_deepQnet import Dist_DQN\n",
        "\n",
        "with open(\"requiredFile.pkl\", \"rb\") as f:\n",
        "    D = pickle.load(f)\n",
        "\n",
        "Xtr = D[\"X_train\"].to_numpy()\n",
        "Xte = D[\"X_test\"].to_numpy()\n",
        "Xnext_tr = D[\"Xnext_train\"].to_numpy()\n",
        "ytr = D[\"y_train\"]\n",
        "yte = D[\"y_test\"]\n",
        "Atr = D[\"Action_train\"]\n",
        "n_actions = D.get(\"nbins\", 25)\n",
        "\n",
        "exps = [\n",
        "    {\"name\": \"exp1_baseline\",  \"seed\": 42, \"gamma\": 0.99, \"lr\": 1e-5, \"epochs\": 100},\n",
        "    {\"name\": \"exp2_gamma095\",  \"seed\": 42, \"gamma\": 0.95, \"lr\": 1e-5, \"epochs\": 100},\n",
        "    {\"name\": \"exp3_higher_lr\", \"seed\": 42, \"gamma\": 0.99, \"lr\": 3e-5, \"epochs\": 100},\n",
        "    {\"name\": \"exp4_seed7\",     \"seed\": 7,  \"gamma\": 0.99, \"lr\": 1e-5, \"epochs\": 100},\n",
        "]\n",
        "\n",
        "def ensure_dir(p): os.makedirs(p, exist_ok=True)\n",
        "\n",
        "def plot_training_loss(log_path, out_png, title):\n",
        "    losses = []\n",
        "    with open(log_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            if \"Loss:\" in line:\n",
        "                try: losses.append(float(line.strip().split(\"Loss:\")[-1]))\n",
        "                except: pass\n",
        "    plt.close(\"all\")\n",
        "    plt.figure(figsize=(6,4), constrained_layout=True)\n",
        "    if losses: plt.plot(losses)\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(title); plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout(); plt.savefig(out_png, dpi=200); plt.close()\n",
        "\n",
        "def plot_train_action_and_survival(A_train, y_train, out_dir, exp_name):\n",
        "    plt.close(\"all\")\n",
        "    plt.figure(figsize=(6,4), constrained_layout=True)\n",
        "    counts = np.bincount(A_train, minlength=n_actions)\n",
        "    plt.bar(range(len(counts)), counts)\n",
        "    plt.xlabel(\"Historical Action (0..24)\"); plt.ylabel(\"Count\")\n",
        "    plt.title(f\"{exp_name} – Training Action Distribution\")\n",
        "    plt.grid(True, axis=\"y\", alpha=0.3)\n",
        "    out1 = os.path.join(out_dir, f\"{exp_name}_train_action_distribution.png\")\n",
        "    plt.savefig(out1, dpi=200); plt.close()\n",
        "\n",
        "    df = pd.DataFrame({\"action\": A_train, \"surv\": (y_train == 0).astype(int)})\n",
        "    by = df.groupby(\"action\")[\"surv\"].mean()\n",
        "    plt.figure(figsize=(6,4), constrained_layout=True)\n",
        "    by.plot(kind=\"bar\"); plt.ylim(0,1)\n",
        "    plt.xlabel(\"Historical Action (0..24)\"); plt.ylabel(\"Survival Rate\")\n",
        "    plt.title(f\"{exp_name} – Training Survival by Action\")\n",
        "    plt.grid(True, axis=\"y\", alpha=0.3)\n",
        "    out2 = os.path.join(out_dir, f\"{exp_name}_train_survival_by_action.png\")\n",
        "    plt.tight_layout(); plt.savefig(out2, dpi=200); plt.close()\n",
        "\n",
        "def policy_figure(q_net, Xtest_np, out_png, exp_name):\n",
        "    with torch.no_grad():\n",
        "        q_vals = q_net(torch.tensor(Xtest_np, dtype=torch.float32))\n",
        "        actions_pred = q_vals.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "    fluid = actions_pred % 5; vaso = actions_pred // 5; N = len(actions_pred)\n",
        "    fluid_prop = np.bincount(fluid, minlength=5).astype(float) / max(N,1)\n",
        "    vaso_prop  = np.bincount(vaso,  minlength=5).astype(float) / max(N,1)\n",
        "    heat = np.zeros((5,5), float)\n",
        "    for f,v in zip(fluid, vaso): heat[v,f]+=1.0\n",
        "    heat_prop = heat / max(N,1)\n",
        "\n",
        "    plt.close(\"all\")\n",
        "    fig = plt.figure(figsize=(15, 4.8), constrained_layout=True)\n",
        "\n",
        "    ax1 = fig.add_subplot(1,3,1)\n",
        "    ax1.bar(range(5), fluid_prop)\n",
        "    ax1.set_xticks(range(5)); ax1.set_xticklabels([f\"F{i}\" for i in range(5)])\n",
        "    ax1.set_ylim(0,1); ax1.set_xlabel(\"Fluid Bin (0..4)\", fontsize=9)\n",
        "    ax1.set_ylabel(\"Proportion\", fontsize=9); ax1.tick_params(labelsize=9)\n",
        "    ax1.set_title(f\"{exp_name}\\nFluid Distribution (Test, Proportion)\", pad=10, fontsize=11)\n",
        "    ax1.grid(True, axis=\"y\", alpha=0.3)\n",
        "\n",
        "    ax2 = fig.add_subplot(1,3,2)\n",
        "    ax2.bar(range(5), vaso_prop)\n",
        "    ax2.set_xticks(range(5)); ax2.set_xticklabels([f\"V{i}\" for i in range(5)])\n",
        "    ax2.set_ylim(0,1); ax2.set_xlabel(\"Vasopressor Bin (0..4)\", fontsize=9)\n",
        "    ax2.set_ylabel(\"Proportion\", fontsize=9); ax2.tick_params(labelsize=9)\n",
        "    ax2.set_title(f\"{exp_name}\\nVasopressor Distribution (Test, Proportion)\", pad=10, fontsize=11)\n",
        "    ax2.grid(True, axis=\"y\", alpha=0.3)\n",
        "\n",
        "    ax3 = fig.add_subplot(1,3,3, projection=\"3d\")\n",
        "    _x = np.arange(5); _y = np.arange(5)\n",
        "    _xx,_yy = np.meshgrid(_x,_y)\n",
        "    x = _xx.ravel(); y = _yy.ravel(); z = np.zeros_like(x, dtype=float)\n",
        "    dx = np.full_like(x, 0.6, float); dy = np.full_like(y, 0.6, float)\n",
        "    dz = heat_prop.ravel()\n",
        "    cmap = cm.get_cmap(\"coolwarm\")\n",
        "    norm = colors.Normalize(vmin=dz.min(), vmax=dz.max() if dz.max()>0 else 1.0)\n",
        "    colors_bar = cmap(norm(dz))\n",
        "    ax3.bar3d(x-0.3, y-0.3, z, dx, dy, dz, color=colors_bar, shade=True)\n",
        "    ax3.set_xticks(range(5)); ax3.set_xticklabels([f\"F{i}\" for i in range(5)], fontsize=8)\n",
        "    ax3.set_yticks(range(5)); ax3.set_yticklabels([f\"V{i}\" for i in range(5)], fontsize=8)\n",
        "    ax3.set_zlabel(\"Proportion\", fontsize=9)\n",
        "    ax3.set_xlabel(\"Fluid Bin\", fontsize=9); ax3.set_ylabel(\"Vasopressor Bin\", fontsize=9)\n",
        "    ax3.set_title(f\"{exp_name}\\n5×5 Action Heatmap (Test, Proportion)\", pad=10, fontsize=11)\n",
        "    mappable = cm.ScalarMappable(norm=norm, cmap=cmap); mappable.set_array([])\n",
        "    cb = fig.colorbar(mappable, ax=ax3, fraction=0.046, pad=0.08)\n",
        "    cb.set_label(\"Proportion\", fontsize=9)\n",
        "\n",
        "    fig.savefig(out_png, dpi=220); plt.close(fig)\n",
        "\n",
        "def summarize_metrics(out_csv, rows):\n",
        "    df = pd.DataFrame(rows)\n",
        "    if os.path.exists(out_csv):\n",
        "        base = pd.read_csv(out_csv); df = pd.concat([base, df], ignore_index=True)\n",
        "    df.to_csv(out_csv, index=False)\n",
        "\n",
        "summary_rows = []\n",
        "for cfg in exps:\n",
        "    name = cfg[\"name\"]; epochs = cfg[\"epochs\"]\n",
        "    outdir = os.path.join(\"runs\", name); ensure_dir(outdir)\n",
        "    print(f\"\\n=== Running {name} (epochs={epochs}, gamma={cfg['gamma']}, lr={cfg['lr']}, seed={cfg['seed']}) ===\")\n",
        "\n",
        "    model = Dist_DQN(state_dim=Xtr.shape[1], num_actions=n_actions,\n",
        "                     gamma=cfg[\"gamma\"], lr=cfg[\"lr\"], seed=cfg[\"seed\"])\n",
        "\n",
        "    log_path = os.path.join(outdir, f\"{name}_training_log.txt\")\n",
        "    open(log_path, \"w\").close()\n",
        "    batchs = {\"state\": Xtr, \"next_state\": Xnext_tr, \"action\": Atr, \"reward\": np.where(ytr==0,24.0,-24.0)}\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        loss = model.train_model(batchs, ep)\n",
        "        print(f\"{name} | Epoch {ep+1}/{epochs} | Loss: {loss:.4f}\")\n",
        "        with open(log_path, \"a\") as lf:\n",
        "            lf.write(f\"Epoch {ep+1} | Loss: {loss:.4f}\\n\")\n",
        "\n",
        "    # save model\n",
        "    model_path = os.path.join(outdir, f\"{name}_model.pt\")\n",
        "    torch.save(model.q_net.state_dict(), model_path)\n",
        "\n",
        "    # plots\n",
        "    policy_png = os.path.join(outdir, f\"{name}_policy_combined.png\")\n",
        "    policy_figure(model.q_net, Xte, policy_png, name)\n",
        "\n",
        "    loss_png = os.path.join(outdir, f\"{name}_training_loss.png\")\n",
        "    plot_training_loss(log_path, loss_png, f\"{name} – Training Loss Over Time\")\n",
        "\n",
        "    plot_train_action_and_survival(Atr, ytr, outdir, name)\n",
        "\n",
        "    # metrics\n",
        "    sr_train = (ytr == 0).mean()\n",
        "    sr_test  = (yte == 0).mean()\n",
        "    er_train = np.where(ytr == 0, 24.0, -24.0).mean()\n",
        "    er_test  = np.where(yte == 0, 24.0, -24.0).mean()\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"experiment\": name, \"epochs\": epochs,\n",
        "        \"gamma\": cfg[\"gamma\"], \"lr\": cfg[\"lr\"], \"seed\": cfg[\"seed\"],\n",
        "        \"survival_train\": sr_train, \"survival_test\": sr_test,\n",
        "        \"exp_return_train\": er_train, \"exp_return_test\": er_test\n",
        "    })\n",
        "\n",
        "summarize_metrics(\"runs/summary_metrics.csv\", summary_rows)\n",
        "print(\"\\nAll 4 experiments complete. Results in runs/exp*/ and runs/summary_metrics.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
